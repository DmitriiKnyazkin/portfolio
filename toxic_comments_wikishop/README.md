# "Токсичные коментарии"
## Цель проекта: постороить модель для определения токсичных коментарий и отправки их на модерацию.
## Данные предоставлены образовательной платформой "Яндекс.Практика" 
## Результат:
	1. Проведена загрузка данных;
	2. Проведена очистка текста;
	3. Проведена токенизация текста;
	4. Проведена лемматизация текста;
	5. Удалены стоп-слова;
	6. Проведена векторизация текстов коментариев;
	7. Подготовлены тренировочный и тестовый набор данных в соотношении 4 -1;
	8. Обучены три модели;
	9. Подобраны гиперпараметры;
	10. Проведена проверка кода на выбоке в 1500 текстов;
	11. Проведена проверка кода на всем дата сете, общая продолжительность подготовки данных на полном объеме данных составила более 30 минут;
	12. Представлена таблица со значениями Accuracy;
	13. Проведена загрузка данных;
	14. Проведена очистка текста;
	15. Проведена токенизация текста;
	16. Проведена лемматизация текста;
	17. Удалены стоп-слова;
	18. Проведена векторизация текстов коментариев;
	19. Подготовлены тренировочный и тестовый набор данных в соотношении 4 -1;
	20. Обучены три модели;
	21. Подобраны гиперпараметры;
	22. Проведена проверка кода на выбоке в 1500 текстов;
	23. Проведена проверка кода на всем дата сете, общая продолжительность подготовки данных на полном объеме данных составила более 30 минут;
	24. Представлена таблица со значениями Accuracy.
## Используемые библиотеки:
	Python, Pandas, nltk.